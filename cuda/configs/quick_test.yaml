# Quick test configuration - validates setup works
# Usage: python scripts/train.py --config configs/quick_test.yaml

base_model: "Qwen/Qwen2.5-Coder-1.5B-Instruct"

# LoRA - minimal for quick test
lora_r: 8
lora_alpha: 16
lora_dropout: 0.05
target_modules:
  - q_proj
  - k_proj

# Training - very short
max_steps: 20
batch_size: 2
gradient_accumulation_steps: 1
learning_rate: 2e-4
warmup_steps: 5
max_seq_length: 1024

# Quantization
use_4bit: true
bnb_4bit_compute_dtype: "float16"
bnb_4bit_quant_type: "nf4"

# Checkpointing
save_steps: 20
logging_steps: 5

# Paths (relative to cuda/)
data_path: "../data/sft/train.jsonl"
output_dir: "../runs/adapters"

seed: 42
use_wandb: false
